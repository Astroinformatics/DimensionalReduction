{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NbSJixlMNV2"
   },
   "source": [
    "# Lab 8: Dimensional Reduction for Classificaiton of Astronomical Images\n",
    "#### [Penn State Astroinformatics Summer School 2022](https://sites.psu.edu/astrostatistics/astroinfo-su22/)\n",
    "#### [Prof. Ashley Villar](http://ashleyvillar.com/menu/about/) (PSU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsgS8gNXzquj"
   },
   "source": [
    "## Overview \n",
    "In this notebook, you will work through an example of incorporating dimensionality reduction techniques into a pipeline for classifying images of galaxies.  You will compare the behavior of two algorithms: \n",
    "- principle component analysis (PCA) and\n",
    "- t-distributed stochastic neighbor embedding (t-sne). \n",
    "\n",
    "This lab builds on previous lessons that introduced of logistic regession, support vector machines (SVMs), methods for evaluating the performance of an ML algorithm, and techniques for training ML models like under sampling.  Feel free to refer back to those lessons as needed.  \n",
    "\n",
    "[//]: # \"TODO: Add links above once have them.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOwx7tnf8hIN"
   },
   "source": [
    "## Installation & Setup\n",
    "The next two code cells merely install and import packages that will be used below.  \n",
    "(Note that the installation will likely take some time to run the first time.  And it's ok if you get lots of messages beginning \"Requirment already satisfied\".  Similarly, it's ok if you get a couple of warnings about environment variables not being set after the cell importing packages.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14292,
     "status": "ok",
     "timestamp": 1651865184297,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "A6Tk97roSSEM",
    "outputId": "4b627685-6559-49a3-d0c7-e9cc23402c87"
   },
   "outputs": [],
   "source": [
    "# Install statement(s)\n",
    "!pip install astroNN\n",
    "!pip install opentsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9514,
     "status": "ok",
     "timestamp": 1651865193792,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "RoR2FQMKSNGY",
    "outputId": "9a653d0f-b8c9-4d6d-e55d-13fd5995a52e"
   },
   "outputs": [],
   "source": [
    "# Import statement(s)\n",
    "from astroNN.datasets import load_galaxy10               # Provides example datasets to be analyzed\n",
    "from astroNN.datasets.galaxy10 import galaxy10cls_lookup # Provides labels for training/evaluating models\n",
    "\n",
    "import numpy as np                                  # Common python package for array maniuplations\n",
    "import matplotlib.pyplot as plt                     # Common python package for plotting\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # Implements Logistic regression\n",
    "from sklearn import svm                             # Implements SVM \n",
    "from sklearn.decomposition import PCA               # Implements PCA\n",
    "#from sklearn.manifold import TSNE                   # Implements t-sne.  Replaced with openTSNE\n",
    "\n",
    "# Tools for easily training and evaluating ML model performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIsLAZO0Q2tq"
   },
   "source": [
    "Next, we'll retreive an array of images (which will be our inputs) and an array of integer labels (which we will use to train/evaluate our models).  Again, this may take some time the first time you run it, as it will download data from the internet.  But it should return within ~10 seconds on subsequent calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21441,
     "status": "ok",
     "timestamp": 1651865215210,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "_wJgE2n4UHIR",
    "outputId": "5e0bde02-7c7b-42b9-ca0a-62557f3e1dab"
   },
   "outputs": [],
   "source": [
    "# Load the RGB images and labels from astroNN\n",
    "images_4d, labels_all = load_galaxy10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLSKsTL6SDt7"
   },
   "source": [
    "## Part 1: Exploratory Data Analysis & Preprocessing\n",
    "\n",
    "Before building a complex model, it's always a good idea to do some basic exploratory data analysis.  First, checking the variables types and array shapes can help reduce bugs.  Second, the intuition that you build by looking at some examples is often helpful in deciding what forms of preprocessing are likely to generate useful features and choose appropriate strategies for training a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK7kCuYvn75S"
   },
   "source": [
    "### Exploring the data\n",
    "First, let's investigate the data stored in images and labels.  \n",
    "1a.  Inspect the output of the following cells to answer the following questions:\n",
    "- What is the *shape* of each individual galaxy image?  \n",
    "- What is the *data type* of the `labels` variable? \n",
    "- If pass one of the `labels` to the `galaxy10cls_lookup()` function, what is returned?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1651865215212,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "RQ9TfbFkS8GM",
    "outputId": "3712fda2-31cc-4f46-ceff-4309d9caf512"
   },
   "outputs": [],
   "source": [
    "images_4d.shape        # Images, x coordinate, y coordinate, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1651865215212,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "2WEK7LR_S4yO",
    "outputId": "3579729c-fbcc-464c-9a68-9b38a5c6d6ae"
   },
   "outputs": [],
   "source": [
    "labels_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1651865215213,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "VOaQ9HEgUuLb",
    "outputId": "e114359c-4d4f-446a-f381-6d6cf0b2cd82"
   },
   "outputs": [],
   "source": [
    "labels_all[0], type(labels_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1651865215213,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "ZTGdJRQjUVKt",
    "outputId": "a6f4572c-115b-4bb7-d2a8-76bed347e4b4"
   },
   "outputs": [],
   "source": [
    " galaxy10cls_lookup(labels_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82YAiYrzUL8G"
   },
   "source": [
    "The next code block demonstrates how to plot a colored image of a single galaxy and how to lookup its galaxy type based on its numerical label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1651865215707,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "nffweYOAy-6T",
    "outputId": "b5904639-f408-4b0b-fadc-0cd300a661fb"
   },
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "plt.imshow(images_4d[img_id]);\n",
    "plt.title(galaxy10cls_lookup(labels_all[img_id]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHYiXJrKVYSU"
   },
   "source": [
    "1b. Modify **img_id** in the cell above and rerun the cell to view several images for several galaxies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdOYkBa5nvjV"
   },
   "source": [
    "### Choosing classes to include in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nY9dEXpCXd4r"
   },
   "source": [
    "1c. Inspect the histogram of the class types. How many classes are there in total? Are the classes *balanced*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 486,
     "status": "ok",
     "timestamp": 1651865216189,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "A-fGEuZJXvO6",
    "outputId": "5468ba4e-c966-4473-e7ea-6bd44cefd80f"
   },
   "outputs": [],
   "source": [
    "plt.hist(labels_all);\n",
    "plt.xlabel('Class number');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMets9QnYF90"
   },
   "source": [
    "1d. Modify `label_id_to_find` in the cell below to inspect an image for each of the unique class of galaxies and its an associated title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1651865216661,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "oxT9n_gVWvsK",
    "outputId": "d1b70a0a-e63b-43fc-dc93-9f5aa02033d3"
   },
   "outputs": [],
   "source": [
    "label_id_to_find = 2\n",
    "first_img_with_label = labels_all[np.where(labels_all==label_id_to_find)][0]\n",
    "plt.imshow(images_4d[first_img_with_label]);\n",
    "plt.title(galaxy10cls_lookup(labels_all[first_img_with_label]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjBmnKGbXnNw"
   },
   "source": [
    "1e. If you were to start by building a model to predict the  classifications of the most common cases, which three values of label would you want to include in your training and testing data sets?\n",
    "\n",
    "1f.  Which pair of galaxy classifications do you anticipate will be hardest for a machine learning algorithm to accurately distinguish?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6DiNNTefdW-"
   },
   "source": [
    "### Preprocessing\n",
    "While storing each image as a 3-d array is useful for visualizing them, many ML packages want their features as a simple 1-d array.  Therefore, we'll flatten the data into a 2-d array, with the first index being the image id and the second index running over all (x,y) coordinates and color values.  \n",
    "\n",
    "We'll also filter the full dataset to pick only a subset of images (and their corresponding labels) to use for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1651865216816,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "jEHt_ZemXCia",
    "outputId": "a149a678-daef-48b8-cb07-8f5e5cfe7cf2"
   },
   "outputs": [],
   "source": [
    "idx_images_to_keep = np.where(labels_all<=2)\n",
    "labels = labels_all[idx_images_to_keep]\n",
    "images_flat = images_4d.reshape(len(images_4d),-1)   # Flatten to a 2_d array\n",
    "images_flat = images_flat[idx_images_to_keep]\n",
    "images_flat.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5EJtpYLbzbL"
   },
   "source": [
    "1f.  Approximately what fraction of the dataset was retained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EH7gCklofmDl"
   },
   "source": [
    "# Part 2: Logistic Regression as a Baseline Model\n",
    "First, we need to split the dataset into a training dataset (e.g., 67%) and test dataset (e.g., 33%) using the `train_test_split` function.  Verify the output sizes are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1651865216981,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "itSGSUOiSQxN",
    "outputId": "2c50094a-d38e-453a-dc76-b33315eedda1"
   },
   "outputs": [],
   "source": [
    "frac_in_testset = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_flat, labels, test_size=frac_in_testset)\n",
    "len(X_train)/len(images_flat), len(X_test)/len(images_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1ZdCDdocixU"
   },
   "source": [
    "Next we'll use the the `LogisticRegression` function to train a generalized linear model to prediction the galaxy class directly from its flattened image.  (By specifying `class_weight` to be `balanced`, we instruct the algorithm to set the weights for each galaxy image inversely proportional to classfrequency of its label in the input dataset.)  This simple model will become our baseline for comparing the performance of more sophisticated models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 152206,
     "status": "ok",
     "timestamp": 1651865369185,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "frziAt8xcoDp",
    "outputId": "e6c2f982-99bd-433e-f3fb-f835b1eb0e59"
   },
   "outputs": [],
   "source": [
    "classifier_lr = LogisticRegression(random_state=0, class_weight='balanced', solver='sag', max_iter=50).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aYcf5Cqebrc"
   },
   "source": [
    "2a.  How how long did it take to train the logistics regression model on the training dataset?  \n",
    "\n",
    "[//]: # \"TODO: How do we extract the runtime from the Jupyter notebook on our server? (In collab, the run time appears in small print below the checkmark to the left of the cell once it's completed running.)\"\n",
    "\n",
    "Did the model fitting procedure converge within the number of itterations alloted?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jl6KALmzgfa0"
   },
   "source": [
    "Next, we'll test our model by asking it to predict the labels for the *test set*.  To assess the performance, we'll compute the accuracy score (i.e., how often the predicted label is correct) and inspect the plot of the confusion matrix for the *test* set below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1651865369647,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "mp3PU-iAmK2v",
    "outputId": "aa9f13f8-a317-4a0a-b1c8-0dc86c8c402d"
   },
   "outputs": [],
   "source": [
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test,y_pred_lr)\n",
    "print(\"Accuracy: \",accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1651865369920,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "-2t9nlMZepYV",
    "outputId": "699373f9-b3bd-4ad4-d669-95cca13bd220"
   },
   "outputs": [],
   "source": [
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "disp_lr = ConfusionMatrixDisplay(confusion_matrix=cm_lr)\n",
    "disp_lr.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-J9hnkQf0vP"
   },
   "source": [
    "2b.  What is the two most common mistakes by the logistic regression classifier?  How does that compare to your prediction from above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KarmZhFrfUKp"
   },
   "source": [
    "Since we're considering three classes, we can't make a simple 2-d plot of the Receiver operating characteristic (ROC) curve, like we could for binary classification.  However, we can still calculate an the area under the curve (AUC) for the ROC curve for each galaxy type and then taken an average of the AUC scores.  (The optional parameter `multi_class` specifies whether we want to compare each pair of classifications (i.e., \"one-vs-one\") or  \"one-verus-rest\") and `average` specifies a weighting scheme for the average.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1651865370105,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "Xq2iD0NUWyp9",
    "outputId": "0a2e132a-0b0b-4b64-84f0-b8d668cd176e"
   },
   "outputs": [],
   "source": [
    "y_pred_prob_lr = classifier_lr.predict_proba(X_test)   \n",
    "macro_roc_auc_ovo_lr = roc_auc_score(y_test, y_pred_prob_lr, multi_class=\"ovo\", average=\"macro\")\n",
    "print(\"AUC (one-vs-one): \",macro_roc_auc_ovo_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c847N5rZnXC3"
   },
   "source": [
    "Once we've trained other classifiers below, we'll look back to compare their accuracy and AUC scores to those of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVGMC1PvNxwX"
   },
   "source": [
    "# Part 3: SVM Baseline\n",
    "\n",
    "Previously we used a linear model due to the significant computational time required to fit a nonlinear classification model to the large volume of image data.  Next, we'll use a [*support vector machine*](https://en.wikipedia.org/wiki/Support-vector_machine) with a [radial basis function kernel](https://en.wikipedia.org/wiki/Radial_basis_function_kernel).\n",
    "\n",
    "In principle, we could apply SVM to the exact same data set.However, the computational cost would be prohibitive.  (Therefore, the code to do that below is intentionally commented out.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651865370106,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "X8nBHBnccrNp"
   },
   "outputs": [],
   "source": [
    "#classifier_svm = svm.SVC(probability=True).fit(X_train, y_train)\n",
    "#classifier_svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC8zGjhUqDA8"
   },
   "source": [
    "In order to make things computationally feasible, we could apply the simplest possible form of dimensional reduction, selecting a subset of the input features.  For example, we could keep every nth pixel value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1651865370107,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "WVkZuZELp1Sd",
    "outputId": "39a01f8c-b8a2-4489-8c74-319b0fa2baeb"
   },
   "outputs": [],
   "source": [
    "keep_every_nth_pixel = 290      # 290 was chosen, so that we'd end up with 50 values from each low-res image\n",
    "X_train_lowres = X_train[:,::keep_every_nth_pixel]\n",
    "X_test_lowres = X_test[:,::keep_every_nth_pixel]\n",
    "X_train_lowres.shape, X_test_lowres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXtXgT56qcC5"
   },
   "source": [
    "3a.  How many pixels are being retained in each image?\n",
    "\n",
    "We can train an SVM classifier using the `svm.SVC` function on the low-resolution version of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 66716,
     "status": "ok",
     "timestamp": 1651865436981,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "RWHNchcdqNBy"
   },
   "outputs": [],
   "source": [
    "classifier_lowres = svm.SVC(probability=True, class_weight='balanced').fit(X_train_lowres, y_train)\n",
    "#classifier_lowres.predict(X_train_lowres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7rmYhDeprUx"
   },
   "source": [
    "\n",
    "And calculate the overall accuracy of this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4939,
     "status": "ok",
     "timestamp": 1651865441900,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "pqQhElujqqFq",
    "outputId": "123457a1-e726-490d-ae92-e3ab06e9e9cb"
   },
   "outputs": [],
   "source": [
    "y_pred_lowres = classifier_lowres.predict(X_test_lowres)\n",
    "accuracy_lowres = accuracy_score(y_test,y_pred_lowres)\n",
    "print(\"Accuracy: \",accuracy_lowres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmB3sG9Uq8n_"
   },
   "source": [
    "3b.  How does the accuracy of the SVM on the low-resolution dataset compare to the accuracy of logistic regression on the full-resolution dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuZA12Hr5tQR"
   },
   "source": [
    "Next, we'll compute the AUC score using the baseline SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5036,
     "status": "ok",
     "timestamp": 1651865446931,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "cEr7rkY0rNC5",
    "outputId": "66d344d9-840a-42d9-e96e-0cdd76dfce6c"
   },
   "outputs": [],
   "source": [
    "y_pred_prob_lowres = classifier_lowres.predict_proba(X_test_lowres)\n",
    "macro_roc_auc_ovo_lowres = roc_auc_score(y_test, y_pred_prob_lowres, multi_class=\"ovo\", average=\"macro\")\n",
    "print(\"AUC: \",macro_roc_auc_ovo_lowres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_YuqbPT53xM"
   },
   "source": [
    "3c. How does the AUC score for the low-resolution SVM model compare to the baseline logistic regression model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WzPDjXt5wrc"
   },
   "source": [
    "Next, we'll inspect the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 5077,
     "status": "ok",
     "timestamp": 1651865451989,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "GmqnS2X0OqB-",
    "outputId": "3de7db29-385b-4b50-ea76-a565f1d4eae6"
   },
   "outputs": [],
   "source": [
    "y_pred_lowres = classifier_lowres.predict(X_test_lowres)\n",
    "cm_lowres = confusion_matrix(y_test, y_pred_lowres)\n",
    "disp_lowres = ConfusionMatrixDisplay(confusion_matrix=cm_lowres)\n",
    "disp_lowres.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_qmnhkeqXrs"
   },
   "source": [
    "3d. How does the confusion matrix for the *test* set using SVM on the low-resolution images compare to the confusion matrix for the *test* set using logistic regression on the full-resolution data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlCGhm99g5Kc"
   },
   "source": [
    "# Part 4: SVM with PCA\n",
    "\n",
    "In Part 3, we used SVM on low-resolution images.  Our astronomical intuition is that the classificaiton would be easier if we could preserve more of the information in the high-resolution images.  [Principal Componets Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) provides an efficient means of performing dimensional reduction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oq39X-qjtIAK"
   },
   "source": [
    "4a.  What do you anticipate the first few principal components might look like?  Once you've made your prediction, run the cell below to plot the first few principal components. (Remember that we need to reshaping them back into images for visualization purposes.) them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22611,
     "status": "ok",
     "timestamp": 1651865474595,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "bs5qRLCo7ILx",
    "outputId": "c1362b5a-99ed-4a01-b2d4-b2661bb3e8a7"
   },
   "outputs": [],
   "source": [
    "num_pca_components = 50\n",
    "pca = PCA(n_components=num_pca_components)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL8zny2h-UwW"
   },
   "source": [
    "First, we will apply PCA to reduce the dimesionality of our images using the `PCA` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1651865475803,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "1E2Zc2VY-21U",
    "outputId": "806bb2a2-b269-43a0-cc06-cf346e412272"
   },
   "outputs": [],
   "source": [
    "plt.imshow(num_pca_components * pca.components_[0,:].clip(0,1/num_pca_components).reshape(69,69,3));\n",
    "plt.show();\n",
    "plt.imshow(num_pca_components * pca.components_[1,:].clip(0,1/num_pca_components).reshape(69,69,3));\n",
    "plt.show();\n",
    "plt.imshow(num_pca_components * pca.components_[2,:].clip(0,1/num_pca_components).reshape(69,69,3));\n",
    "plt.show();\n",
    "plt.imshow(num_pca_components * pca.components_[3,:].clip(0,1/num_pca_components).reshape(69,69,3));\n",
    "plt.show();\n",
    "plt.imshow(num_pca_components * pca.components_[4,:].clip(0,1/num_pca_components).reshape(69,69,3));\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lI12CfJtHkN"
   },
   "source": [
    "4b.  How do the actual principal components compare to your predictions?  Try to qualitatively explain what each principal component captures.  \n",
    "\n",
    "4c.  Roughly what fraction of the variance in the images might you guess could be explained with the first few principal components?  \n",
    "\n",
    "We can print the fraction of the variance explained by each of the PCA components.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1651865475804,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "y_YthLbetiUj",
    "outputId": "ff9ff3e1-51fa-43d7-d769-378425c7fedc"
   },
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvABnTlWwWFI"
   },
   "source": [
    "or plot the cumulative fraction of the variance explained by the first n PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1651865476029,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "F3ZGSEB0wDPT",
    "outputId": "df067f45-685c-43f7-c6ca-ee3f3018f2e4"
   },
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_.cumsum());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8EGGitrtIPf"
   },
   "source": [
    "4d.  How did you guess compare to the actual fraction of variance explained?\n",
    "\n",
    "Next, let us project the images onto the principal components.  \n",
    "Then we'll plot the first two PCA scores which can become low-dimensional features and color codethe points according to the galaxy classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2106,
     "status": "ok",
     "timestamp": 1651865478132,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "kv-eDMRwnKSN",
    "outputId": "88d00829-f731-4101-e3ad-4ec48fec2cd7"
   },
   "outputs": [],
   "source": [
    "X_train_PCA = pca.transform(X_train)\n",
    "\n",
    "for i in np.unique(y_train):\n",
    "  index_images_with_label = np.where(y_train==i)\n",
    "  plt.plot(X_train_PCA[index_images_with_label[0],0],X_train_PCA[index_images_with_label[0],1],'.',markersize=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psTAPDK13DlK"
   },
   "source": [
    "4e.  Do you see natural clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1SrePDEZi8z"
   },
   "source": [
    "Now, we'll train an SVM classifier using the `svm.SVC` function on the training set of PCA scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 47329,
     "status": "ok",
     "timestamp": 1651865525458,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "BaR35GJ2_0zB"
   },
   "outputs": [],
   "source": [
    "clf_pca = svm.SVC(probability=True, class_weight='balanced').fit(X_train_PCA, y_train)\n",
    "#clf_pca.predict(X_train_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjaZEAoH6Tju"
   },
   "source": [
    "As before, let's compute the accuracy score and AUC score for the SVM based on the PCA scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4858,
     "status": "ok",
     "timestamp": 1651865530294,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "v86qntzi3CXg",
    "outputId": "99df7e58-7bea-49ef-fe3f-64777069df8b"
   },
   "outputs": [],
   "source": [
    "X_test_PCA = pca.transform(X_test)\n",
    "y_pred_pca = clf_pca.predict(X_test_PCA)\n",
    "accuracy_pca = accuracy_score(y_test,y_pred_pca)\n",
    "print(\"Accuracy: \",accuracy_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4073,
     "status": "ok",
     "timestamp": 1651865534352,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "j1I33QoS4yiJ",
    "outputId": "70a04cc4-f9d0-4f48-a98d-54d7fb5e8efa"
   },
   "outputs": [],
   "source": [
    "y_pred_prob_pca = clf_pca.predict_proba(X_test_PCA)\n",
    "macro_roc_auc_ovo_pca = roc_auc_score(y_test, y_pred_prob_pca, multi_class=\"ovo\", average=\"macro\")\n",
    "print(\"AUC: \",macro_roc_auc_ovo_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGJRadj76Puk"
   },
   "source": [
    "4f. How do the accuracy and AUC scores compare to that of the SVM based on low-res versions of the galaxy images?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oz4VgQs-7BC_"
   },
   "source": [
    "Now, we'll plot a confusion matrix for the *test* set using the SVM trained on the PCA scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1651865534537,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "hI9YCFF74z39",
    "outputId": "f931bedc-c0e0-4da5-bd36-17a2701a6b5a"
   },
   "outputs": [],
   "source": [
    "cm_pca = confusion_matrix(y_test, y_pred_pca)\n",
    "disp_pca = ConfusionMatrixDisplay(confusion_matrix=cm_pca)\n",
    "disp_pca.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZimJeVhv7doD"
   },
   "source": [
    "4g.  How does the confusion matrix for the SVM using PCA scores as features compare to the confusion matrix for the SVM trained on low-res galaxy images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb3_QJR97qYW"
   },
   "source": [
    "4h. How does the performance change if you increase or reduce the number of PCA scores used as features to the SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-qHWhMOas-H"
   },
   "source": [
    "# Part 5: Classification with t-sne\n",
    "\n",
    "Finally, we will explore classification of the same galaxy images, but using the outputs of t-sne as features to the SVM. Note that this is *not* typically used for classifcation tasks, and we will see why.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5et9Y3G-lnp"
   },
   "source": [
    "First, we'll reduce the dimensionality of the PCA features.\n",
    "For this, we will use the `TSNE` function from the `openTSNE` module. Note that `sklearn` also has a version of `tsne`; however, the `openTSNE` version will be much faster for our problem.\n",
    "TSNE does not scale well with dimensionality.  Therefore, it is typically very helpful to begin in a lower dimensional space.  For example, we could use the PCA scores from Part 4 as inputs to t-sne.\n",
    "It can also be useful to fit tsne to a subset of the fully dataset for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 143920,
     "status": "ok",
     "timestamp": 1651865678453,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "yZfq5BLnAILq"
   },
   "outputs": [],
   "source": [
    "from openTSNE import TSNE\n",
    "\n",
    "tsne_200 = TSNE(n_components=2, perplexity=200)\n",
    "\n",
    "X_train_tsne_200 = tsne_200.fit(X_train_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8PC4PII_cxs"
   },
   "source": [
    "Let's visualize the reduced latent space from t-sne using a scatter plot and coloring each point by the galaxy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1651865678809,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "9yh0ZOCm3a06",
    "outputId": "aaac805e-f3a4-4623-a138-6f40b2baaec9"
   },
   "outputs": [],
   "source": [
    "for i in np.unique(y_train):\n",
    "  index_images_with_label = np.where(y_train==i)\n",
    "  plt.plot(X_train_tsne_200[index_images_with_label[0],0],X_train_tsne_200[index_images_with_label[0],1],'.')\n",
    "  plt.plot('t-sne component 1')\n",
    "  plt.plot('t-sne component 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhFsd832_tN4"
   },
   "source": [
    "5a.  How do the first two t-sne features compare to the first two PCA scores?  Do you expect that these will be useful for classifying galaxies with a SVM?  \n",
    "\n",
    "Try rerunning t-sne.  Since it's a stochastic algorithm, we expect the specific results might change from one run to the next.  Do you expect the run-to-run variations will affect their utility for classification?\n",
    "\n",
    "Next, try rerunning t-sne, but using a few different values for the perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 82149,
     "status": "ok",
     "timestamp": 1651865760954,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "k5iovnEPAiM7",
    "outputId": "3cda2b43-ee98-4827-fdbf-bd5f4d8c892e"
   },
   "outputs": [],
   "source": [
    "tsne_alt = TSNE(n_components=2, perplexity=5)\n",
    "X_train_tsne_alt = tsne_alt.fit(X_train_PCA)\n",
    "\n",
    "for i in np.unique(y_train):\n",
    "  index_images_with_label = np.where(y_train==i)\n",
    "  plt.plot(X_train_tsne_alt[index_images_with_label[0],0],X_train_tsne_alt[index_images_with_label[0],1],'.')\n",
    "  plt.plot('t-sne component 1')\n",
    "  plt.plot('t-sne component 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLeUEJl-A-mM"
   },
   "source": [
    "5b. How does the choice of the perplexity parameter impact the latent space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZZ3H2E6drJn"
   },
   "source": [
    "Now, we can train an SVM classifier with the outputs of the t-sne algorithm as the features for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 49417,
     "status": "ok",
     "timestamp": 1651866454172,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "ocFZyx-0y10j"
   },
   "outputs": [],
   "source": [
    "classifier_tsne = svm.SVC(probability=True, class_weight='balanced').fit(X_train_tsne_200, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNbX6jaxI8OE"
   },
   "source": [
    "As before, we can calculate the overall accuracy of this model and its AUC score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23997,
     "status": "ok",
     "timestamp": 1651866786804,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "XFt1_F1NBrGq",
    "outputId": "2621f99f-4102-4627-fe8c-39cc105c29da"
   },
   "outputs": [],
   "source": [
    "X_test_tsne_200 = X_train_tsne_200.transform(X_test_PCA)\n",
    "y_pred_tsne_200 = classifier_tsne.predict(X_test_tsne_200)\n",
    "accuracy_tsne_200 = accuracy_score(y_test,y_pred_tsne_200)\n",
    "print(\"Accuracy: \", accuracy_tsne_200)\n",
    "\n",
    "y_pred_prob_tsne_200 = classifier_tsne.predict_proba(X_test_tsne_200)\n",
    "macro_roc_auc_ovo_tsne_200 = roc_auc_score(y_test, y_pred_prob_tsne_200, multi_class=\"ovo\", average=\"macro\")\n",
    "print(\"AUC: \", macro_roc_auc_ovo_tsne_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpUFN9oTJHzc"
   },
   "source": [
    "5c.  How do the accuracy and AUC scores compare to those of our previous methods?  Why do you think this is (think back to your visualization of the latent space)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmGnZfhMBH06"
   },
   "source": [
    "Similarly, we can plot the confusion matrix for the test set based on an SVM with the t-sne outputs as its input features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1651866814370,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "wag3_RMsW3B8",
    "outputId": "8ec0f1bb-433e-4cf9-d773-68ea630a4b59"
   },
   "outputs": [],
   "source": [
    "cm_tsne_200 = confusion_matrix(y_test, y_pred_tsne_200)\n",
    "disp_tsne_200 = ConfusionMatrixDisplay(confusion_matrix=cm_tsne_200)\n",
    "disp_tsne_200.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCThfwBxBIkO"
   },
   "source": [
    "5d.  How does this confusion_matrix compare to the confusion matrix using the other algorithms and features?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbKUeAdaLG7v"
   },
   "source": [
    "## To learn more\n",
    "- [How to use t-SNE effectively](https://distill.pub/2016/misread-tsne/)\n",
    "- [Dimensionality Reduction for Data Visualization](https://towardsdatascience.com/dimensionality-reduction-for-data-visualization-pca-vs-tsne-vs-umap-be4aa7b1cb29)\n",
    "- [Explore U-Map](https://grantcuster.github.io/umap-explorer/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1651865819770,
     "user": {
      "displayName": "V. Ashley Villar",
      "userId": "02362468542335012237"
     },
     "user_tz": 240
    },
    "id": "5JHeWQVcLsSa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "IsgS8gNXzquj",
    "XOwx7tnf8hIN",
    "tLSKsTL6SDt7",
    "iK7kCuYvn75S",
    "BdOYkBa5nvjV",
    "u6DiNNTefdW-",
    "EH7gCklofmDl",
    "DVGMC1PvNxwX",
    "wlCGhm99g5Kc",
    "W-qHWhMOas-H"
   ],
   "name": "Astroinformatics Lab Dimensional Reduction Galaxy images.ipynb",
   "provenance": [
    {
     "file_id": "1Fg7doFVZd9WSUDs3HsL5pW3HzzkiTztE",
     "timestamp": 1650308608970
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
